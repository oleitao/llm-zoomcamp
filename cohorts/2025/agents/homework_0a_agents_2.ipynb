{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework: Agents\n",
    "\n",
    "In this homework, we will learn more about function calling, and we will also explore MCP - model-context protocol."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation\n",
    "\n",
    "First, we'll define the functions that we will use when building our agent. They will generate and set fake weather data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Pre-defined weather data for a specific city\n",
    "known_weather_data = {\n",
    "    'berlin': 20.0\n",
    "}\n",
    "\n",
    "def get_weather(city: str) -> float:\n",
    "    \"\"\"Retrieves the temperature for a specified city.\"\"\"\n",
    "    # Clean and standardize the city name\n",
    "    city = city.strip().lower()\n",
    "\n",
    "    # Check if the city is in our known data\n",
    "    if city in known_weather_data:\n",
    "        return known_weather_data[city]\n",
    "\n",
    "    # If not, generate a random temperature\n",
    "    return round(random.uniform(-5, 35), 1)\n",
    "\n",
    "\n",
    "def set_weather(city: str, temp: float) -> str:\n",
    "    \"\"\"Sets the temperature for a specified city.\"\"\"\n",
    "    # Clean and standardize the city name\n",
    "    city = city.strip().lower()\n",
    "    # Update the known weather data with the new temperature\n",
    "    known_weather_data[city] = temp\n",
    "    # Return a confirmation message\n",
    "    return 'OK'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1. Define function description\n",
    "\n",
    "We want to use `get_weather` as a tool for our agent, so we need to describe it in a format the LLM can understand. This involves defining its name, purpose, parameters, and which parameters are required.\n",
    "\n",
    "- **TODO1 (name):** The name of the function is `get_weather`.\n",
    "- **TODO2 (description):** A clear, concise description of what the function does. \"Get the current temperature for a given city.\" is a good choice.\n",
    "- **TODO3 (parameter name):** The function takes one parameter, which is `city`.\n",
    "- **TODO4 (parameter description):** A description of the parameter. \"The city for which to get the weather\" clearly explains its purpose.\n",
    "- **TODO5 (required):** The `city` parameter is essential for the function to work, so it must be included in the `required` list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The value for TODO3 is: 'city'\n"
     ]
    }
   ],
   "source": [
    "get_weather_tool = {\n",
    "    \"type\": \"function\",\n",
    "    # The 'function' key is standard for OpenAI tool definitions.\n",
    "    \"function\": {\n",
    "        \"name\": \"get_weather\",\n",
    "        \"description\": \"Get the current temperature for a given city.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"city\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The city for which to get the weather, e.g. Berlin\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"city\"],\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "print(f\"The value for TODO3 is: '{list(get_weather_tool['function']['parameters']['properties'].keys())[0]}'\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1 (Optional) Testing the Tool\n",
    "\n",
    "To test if our tool definition works, we can make a call to an LLM (like OpenAI's GPT models) and see if it correctly identifies that it needs to use our `get_weather` tool based on a user's prompt. We'll simulate a conversation where the user asks for the weather."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulating an API call to test the tool definition.\n",
      "User prompt: What's the weather like in Berlin?\n",
      "--- Mock LLM Response ---\n",
      "LLM wants to call function: get_weather\n",
      "With arguments: {'city': 'Berlin'}\n",
      "\n",
      "Calling our local get_weather() function...\n",
      "Result: 20.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "import json\n",
    "\n",
    "# To run this, you need an OpenAI API key.\n",
    "# You can set it as an environment variable 'OPENAI_API_KEY'\n",
    "# client = OpenAI()\n",
    "\n",
    "# Since we don't want to make a real API call, we'll mock the client and response.\n",
    "# This is how a real response would look.\n",
    "mock_response = {\n",
    "    'choices': [\n",
    "        {\n",
    "            'message': {\n",
    "                'role': 'assistant',\n",
    "                'tool_calls': [\n",
    "                    {\n",
    "                        'id': 'call_abc123',\n",
    "                        'type': 'function',\n",
    "                        'function': {\n",
    "                            'name': 'get_weather',\n",
    "                            'arguments': '{\\n  \"city\": \"Berlin\"\\n}'\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"Simulating an API call to test the tool definition.\")\n",
    "print(\"User prompt: What's the weather like in Berlin?\")\n",
    "print(\"--- Mock LLM Response ---\")\n",
    "\n",
    "# The response contains a 'tool_calls' object, indicating the LLM wants to use our function.\n",
    "tool_call = mock_response['choices'][0]['message']['tool_calls'][0]\n",
    "function_name = tool_call['function']['name']\n",
    "function_args = json.loads(tool_call['function']['arguments'])\n",
    "\n",
    "print(f\"LLM wants to call function: {function_name}\")\n",
    "print(f\"With arguments: {function_args}\")\n",
    "\n",
    "# Now we would call our actual Python function with these arguments\n",
    "if function_name == 'get_weather':\n",
    "    weather_result = get_weather(city=function_args.get('city'))\n",
    "    print(f\"\\nCalling our local get_weather() function...\\nResult: {weather_result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2. Adding another tool\n",
    "\n",
    "Next, we'll write a description for the `set_weather` function. This function takes two parameters: `city` (a string) and `temp` (a float). Both are required.\n",
    "\n",
    "The description should clearly state that this function sets or updates the weather data. The parameters section must define both `city` and `temp`, specifying their types (`string` and `number`) and what they represent. Finally, the `required` array must list both `'city'` and `'temp'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Description for set_weather function:\n",
      "{\n",
      "  \"type\": \"function\",\n",
      "  \"function\": {\n",
      "    \"name\": \"set_weather\",\n",
      "    \"description\": \"Set or update the temperature for a specified city in the database.\",\n",
      "    \"parameters\": {\n",
      "      \"type\": \"object\",\n",
      "      \"properties\": {\n",
      "        \"city\": {\n",
      "          \"type\": \"string\",\n",
      "          \"description\": \"The name of the city, e.g. London\"\n",
      "        },\n",
      "        \"temp\": {\n",
      "          \"type\": \"number\",\n",
      "          \"description\": \"The temperature to set for the city.\"\n",
      "        }\n",
      "      },\n",
      "      \"required\": [\n",
      "        \"city\",\n",
      "        \"temp\"\n",
      "      ]\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "set_weather_tool = {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"set_weather\",\n",
    "        \"description\": \"Set or update the temperature for a specified city in the database.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"city\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The name of the city, e.g. London\"\n",
    "                },\n",
    "                \"temp\": {\n",
    "                    \"type\": \"number\",\n",
    "                    \"description\": \"The temperature to set for the city.\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"city\", \"temp\"]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Description for set_weather function:\")\n",
    "print(json.dumps(set_weather_tool, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3. Install FastMCP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: fastmcp\n",
      "Version: 2.10.5\n",
      "Summary: The fast, Pythonic way to build MCP servers and clients.\n",
      "Home-page: https://gofastmcp.com\n",
      "Author: Jeremiah Lowin\n",
      "Author-email: \n",
      "License-Expression: Apache-2.0\n",
      "Location: /home/dan/environments/.env_dataeng/lib/python3.10/site-packages\n",
      "Requires: authlib, cyclopts, exceptiongroup, httpx, mcp, openapi-pydantic, pydantic, pyperclip, python-dotenv, rich\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show fastmcp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4. Simple MCP Server\n",
    "\n",
    "We will create a simple MCP server using our weather functions. First, let's create the `weather_server.py` file. We need to add proper docstrings to our functions so `FastMCP` can automatically generate the tool descriptions.\n",
    "\n",
    "When we run this server script from the command line, it will print a startup message. This message indicates how the server is communicating. The part we are looking for is the transport method.\n",
    "\n",
    "```\n",
    "Starting MCP server 'Weather Service 🌦️' with transport 'stdio'\n",
    "```\n",
    "\n",
    "The value instead of `<TODO>` is **stdio**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting weather_server.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile weather_server.py\n",
    "import random\n",
    "from fastmcp import FastMCP\n",
    "\n",
    "# Initialize the MCP server with a name\n",
    "mcp = FastMCP(\"Weather Service 🌦️\")\n",
    "\n",
    "# Pre-defined weather data\n",
    "known_weather_data = {\n",
    "    'berlin': 20.0\n",
    "}\n",
    "\n",
    "# The @mcp.tool decorator registers the function as an available tool\n",
    "@mcp.tool\n",
    "def get_weather(city: str) -> float:\n",
    "    \"\"\"\n",
    "    Retrieves the temperature for a specified city.\n",
    "\n",
    "    Parameters:\n",
    "        city (str): The name of the city for which to retrieve weather data.\n",
    "\n",
    "    Returns:\n",
    "        float: The temperature associated with the city.\n",
    "    \"\"\"\n",
    "    city = city.strip().lower()\n",
    "    if city in known_weather_data:\n",
    "        return known_weather_data[city]\n",
    "    return round(random.uniform(-5, 35), 1)\n",
    "\n",
    "@mcp.tool\n",
    "def set_weather(city: str, temp: float) -> str:\n",
    "    \"\"\"\n",
    "    Sets the temperature for a specified city.\n",
    "\n",
    "    Parameters:\n",
    "        city (str): The name of the city for which to set the weather data.\n",
    "        temp (float): The temperature to associate with the city.\n",
    "\n",
    "    Returns:\n",
    "        str: A confirmation string 'OK' indicating successful update.\n",
    "    \"\"\"\n",
    "    city = city.strip().lower()\n",
    "    known_weather_data[city] = temp\n",
    "    return 'OK'\n",
    "\n",
    "# This block ensures the server runs only when the script is executed directly\n",
    "if __name__ == \"__main__\":\n",
    "    mcp.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request:\n",
      "{\n",
      "  \"jsonrpc\": \"2.0\",\n",
      "  \"id\": 3,\n",
      "  \"method\": \"tools/call\",\n",
      "  \"params\": {\n",
      "    \"name\": \"get_weather\",\n",
      "    \"arguments\": {\n",
      "      \"city\": \"Berlin\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "Response:\n",
      "{\n",
      "  \"jsonrpc\": \"2.0\",\n",
      "  \"id\": 3,\n",
      "  \"result\": 20.0\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "## Q5. Protocol\n",
    "# Simulate calling the tool manually\n",
    "import json\n",
    "\n",
    "rpc_request = {\n",
    "    \"jsonrpc\": \"2.0\",\n",
    "    \"id\": 3,\n",
    "    \"method\": \"tools/call\",\n",
    "    \"params\": {\n",
    "        \"name\": \"get_weather\",\n",
    "        \"arguments\": {\n",
    "            \"city\": \"Berlin\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Request:\")\n",
    "print(json.dumps(rpc_request, indent=2))\n",
    "\n",
    "# Simulate handling\n",
    "response = get_weather(**rpc_request[\"params\"][\"arguments\"])\n",
    "rpc_response = {\n",
    "    \"jsonrpc\": \"2.0\",\n",
    "    \"id\": rpc_request[\"id\"],\n",
    "    \"result\": response\n",
    "}\n",
    "\n",
    "print(\"\\nResponse:\")\n",
    "print(json.dumps(rpc_response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "## Q6. Client\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running Q6 Client Test ---\n",
      "Attempting to connect to the MCP server...\n",
      "Connection successful. Listing tools...\n",
      "\n",
      "--- Available Tools Found ---\n",
      "Converting Tool objects to a JSON-serializable format...\n",
      "[\n",
      "  {\n",
      "    \"name\": \"get_weather\",\n",
      "    \"title\": null,\n",
      "    \"description\": \"Retrieves the temperature for a specified city.\\n\\nParameters:\\n    city (str): The name of the city for which to retrieve weather data.\\n\\nReturns:\\n    float: The temperature associated with the city.\",\n",
      "    \"inputSchema\": {\n",
      "      \"properties\": {\n",
      "        \"city\": {\n",
      "          \"title\": \"City\",\n",
      "          \"type\": \"string\"\n",
      "        }\n",
      "      },\n",
      "      \"required\": [\n",
      "        \"city\"\n",
      "      ],\n",
      "      \"type\": \"object\"\n",
      "    },\n",
      "    \"outputSchema\": {\n",
      "      \"properties\": {\n",
      "        \"result\": {\n",
      "          \"title\": \"Result\",\n",
      "          \"type\": \"number\"\n",
      "        }\n",
      "      },\n",
      "      \"required\": [\n",
      "        \"result\"\n",
      "      ],\n",
      "      \"title\": \"_WrappedResult\",\n",
      "      \"type\": \"object\",\n",
      "      \"x-fastmcp-wrap-result\": true\n",
      "    },\n",
      "    \"annotations\": null,\n",
      "    \"meta\": null\n",
      "  },\n",
      "  {\n",
      "    \"name\": \"set_weather\",\n",
      "    \"title\": null,\n",
      "    \"description\": \"Sets the temperature for a specified city.\\n\\nParameters:\\n    city (str): The name of the city for which to set the weather data.\\n    temp (float): The temperature to associate with the city.\\n\\nReturns:\\n    str: A confirmation string 'OK' indicating successful update.\",\n",
      "    \"inputSchema\": {\n",
      "      \"properties\": {\n",
      "        \"city\": {\n",
      "          \"title\": \"City\",\n",
      "          \"type\": \"string\"\n",
      "        },\n",
      "        \"temp\": {\n",
      "          \"title\": \"Temp\",\n",
      "          \"type\": \"number\"\n",
      "        }\n",
      "      },\n",
      "      \"required\": [\n",
      "        \"city\",\n",
      "        \"temp\"\n",
      "      ],\n",
      "      \"type\": \"object\"\n",
      "    },\n",
      "    \"outputSchema\": {\n",
      "      \"properties\": {\n",
      "        \"result\": {\n",
      "          \"title\": \"Result\",\n",
      "          \"type\": \"string\"\n",
      "        }\n",
      "      },\n",
      "      \"required\": [\n",
      "        \"result\"\n",
      "      ],\n",
      "      \"title\": \"_WrappedResult\",\n",
      "      \"type\": \"object\",\n",
      "      \"x-fastmcp-wrap-result\": true\n",
      "    },\n",
      "    \"annotations\": null,\n",
      "    \"meta\": null\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import json\n",
    "from fastmcp import Client\n",
    "import weather_server # Import the server module when in a notebook\n",
    "import nest_asyncio\n",
    "\n",
    "# Apply the patch to allow nested event loops in Jupyter\n",
    "nest_asyncio.apply()\n",
    "\n",
    "async def main():\n",
    "    \"\"\"\n",
    "    An async function that connects to the MCP server and lists the available tools\n",
    "    using the correct `list_tools()` method.\n",
    "    \"\"\"\n",
    "    print(\"Attempting to connect to the MCP server...\")\n",
    "    async with Client(weather_server.mcp) as mcp_client:\n",
    "        print(\"Connection successful. Listing tools...\")\n",
    "        # The correct method to get the list of tool objects is `list_tools()`.\n",
    "        tools = await mcp_client.list_tools()\n",
    "    return tools\n",
    "\n",
    "# Now we can run the async main function\n",
    "print(\"--- Running Q6 Client Test ---\")\n",
    "available_tools = asyncio.run(main())\n",
    "\n",
    "# Print the result if found\n",
    "if available_tools:\n",
    "    print(\"\\n--- Available Tools Found ---\")\n",
    "    \n",
    "    # --- JSON Serialization Fix ---\n",
    "    # The result `available_tools` is a list of custom `Tool` objects.\n",
    "    # The `json.dumps` function throws a TypeError because it doesn't know\n",
    "    # how to convert these custom objects into a JSON string.\n",
    "    # We can solve this by converting the list of objects into a list of dictionaries\n",
    "    # using a list comprehension and Python's built-in `vars()` function.\n",
    "    print(\"Converting Tool objects to a JSON-serializable format...\")\n",
    "    serializable_tools = [vars(tool) for tool in available_tools]\n",
    "\n",
    "    # Now, `json.dumps` will work correctly with the list of dictionaries.\n",
    "    print(json.dumps(serializable_tools, indent=2))\n",
    "\n",
    "else:\n",
    "    print(\"\\nCould not retrieve the list of tools.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q6: List tools and call get_weather using FastMCP Client in Jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Available Tools (Q6) ---\n",
      "name='get_weather' title=None description='Retrieves the temperature for a specified city.\\n\\nParameters:\\n    city (str): The name of the city for which to retrieve weather data.\\n\\nReturns:\\n    float: The temperature associated with the city.' inputSchema={'properties': {'city': {'title': 'City', 'type': 'string'}}, 'required': ['city'], 'type': 'object'} outputSchema={'properties': {'result': {'title': 'Result', 'type': 'number'}}, 'required': ['result'], 'title': '_WrappedResult', 'type': 'object', 'x-fastmcp-wrap-result': True} annotations=None meta=None\n",
      "name='set_weather' title=None description=\"Sets the temperature for a specified city.\\n\\nParameters:\\n    city (str): The name of the city for which to set the weather data.\\n    temp (float): The temperature to associate with the city.\\n\\nReturns:\\n    str: A confirmation string 'OK' indicating successful update.\" inputSchema={'properties': {'city': {'title': 'City', 'type': 'string'}, 'temp': {'title': 'Temp', 'type': 'number'}}, 'required': ['city', 'temp'], 'type': 'object'} outputSchema={'properties': {'result': {'title': 'Result', 'type': 'string'}}, 'required': ['result'], 'title': '_WrappedResult', 'type': 'object', 'x-fastmcp-wrap-result': True} annotations=None meta=None\n",
      "\n",
      "--- Call get_weather (Q5) ---\n",
      "Result of get_weather for Berlin: CallToolResult(content=[TextContent(type='text', text='20.0', annotations=None, meta=None)], structured_content={'result': 20.0}, data=20.0, is_error=False)\n"
     ]
    }
   ],
   "source": [
    "# Q6: List tools and call get_weather using FastMCP Client in Jupyter\n",
    "import asyncio\n",
    "from fastmcp import Client\n",
    "import weather_server\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "async def main():\n",
    "    async with Client(weather_server.mcp) as mcp_client:\n",
    "        print(\"--- Available Tools (Q6) ---\")\n",
    "        tools = await mcp_client.list_tools()\n",
    "        for tool in tools:\n",
    "            print(tool)\n",
    "        print(\"\\n--- Call get_weather (Q5) ---\")\n",
    "        result = await mcp_client.call_tool(\"get_weather\", {\"city\": \"Berlin\"})\n",
    "        print(\"Result of get_weather for Berlin:\", result)\n",
    "\n",
    "await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started server with command: python weather_server.py\n",
      "Sending initialize request...\n",
      "Initialize response: {'protocolVersion': '2024-11-05', 'capabilities': {'experimental': {}, 'prompts': {'listChanged': False}, 'resources': {'subscribe': False, 'listChanged': False}, 'tools': {'listChanged': True}}, 'serverInfo': {'name': 'Weather Service 🌦️', 'version': '1.11.0'}}\n",
      "Sending initialized notification...\n",
      "Handshake completed successfully\n",
      "Retrieving available tools...\n",
      "Available tools: ['get_weather', 'set_weather']\n",
      "--- Available Tools (Q6) ---\n",
      "[{'name': 'get_weather', 'description': 'Retrieves the temperature for a specified city.\\n\\nParameters:\\n    city (str): The name of the city for which to retrieve weather data.\\n\\nReturns:\\n    float: The temperature associated with the city.', 'inputSchema': {'properties': {'city': {'title': 'City', 'type': 'string'}}, 'required': ['city'], 'type': 'object'}, 'outputSchema': {'properties': {'result': {'title': 'Result', 'type': 'number'}}, 'required': ['result'], 'title': '_WrappedResult', 'type': 'object', 'x-fastmcp-wrap-result': True}}, {'name': 'set_weather', 'description': \"Sets the temperature for a specified city.\\n\\nParameters:\\n    city (str): The name of the city for which to set the weather data.\\n    temp (float): The temperature to associate with the city.\\n\\nReturns:\\n    str: A confirmation string 'OK' indicating successful update.\", 'inputSchema': {'properties': {'city': {'title': 'City', 'type': 'string'}, 'temp': {'title': 'Temp', 'type': 'number'}}, 'required': ['city', 'temp'], 'type': 'object'}, 'outputSchema': {'properties': {'result': {'title': 'Result', 'type': 'string'}}, 'required': ['result'], 'title': '_WrappedResult', 'type': 'object', 'x-fastmcp-wrap-result': True}}]\n",
      "Calling tool 'get_weather' with arguments: {'city': 'Berlin'}\n",
      "\n",
      "--- Call get_weather (Q5) ---\n",
      "{'content': [{'type': 'text', 'text': '20.0'}], 'structuredContent': {'result': 20.0}, 'isError': False}\n"
     ]
    }
   ],
   "source": [
    "#with the code and client provided in the homework\n",
    "import mcp_client\n",
    "\n",
    "# Start the MCP server and client\n",
    "our_mcp_client = mcp_client.MCPClient([\"python\", \"weather_server.py\"])\n",
    "our_mcp_client.start_server()\n",
    "our_mcp_client.initialize()\n",
    "our_mcp_client.initialized()\n",
    "\n",
    "# Q6: List available tools\n",
    "tools = our_mcp_client.get_tools()\n",
    "print(\"--- Available Tools (Q6) ---\")\n",
    "print(tools)\n",
    "\n",
    "# Q5: Call get_weather for Berlin\n",
    "result = our_mcp_client.call_tool('get_weather', {'city': 'Berlin'})\n",
    "print(\"\\n--- Call get_weather (Q5) ---\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "class MCPTools:\n",
    "    def __init__(self, mcp_client):\n",
    "        self.mcp_client = mcp_client\n",
    "        self.tools = None\n",
    "    \n",
    "    def get_tools(self):\n",
    "        if self.tools is None:\n",
    "            mcp_tools = self.mcp_client.get_tools()\n",
    "            self.tools = convert_tools_list(mcp_tools)\n",
    "        return self.tools\n",
    "\n",
    "    def function_call(self, tool_call_response):\n",
    "        function_name = tool_call_response.name\n",
    "        arguments = json.loads(tool_call_response.arguments)\n",
    "\n",
    "        result = self.mcp_client.call_tool(function_name, arguments)\n",
    "\n",
    "        return {\n",
    "            \"type\": \"function_call_output\",\n",
    "            \"call_id\": tool_call_response.call_id,\n",
    "            \"output\": json.dumps(result, indent=2),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Key loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# This line loads the environment variables from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Now you can access the API key using os.getenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# It's good practice to check if the key was loaded successfully\n",
    "if not api_key:\n",
    "    raise ValueError(\"API_KEY not found. Make sure it's set in your .env file.\")\n",
    "\n",
    "# You can now use the api_key variable to connect to your service\n",
    "print(\"API Key loaded successfully!\")\n",
    "# Example: client = YourApiService(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = \"gpt-4.1-nano-2025-04-14\"\n",
    "# def llm(prompt):\n",
    "#     response = client.chat.completions.create(\n",
    "#         model= model, #'gpt-4o-mini',\n",
    "#         messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "#     )\n",
    "    \n",
    "#     return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started server with command: python weather_server.py\n",
      "Sending initialize request...\n",
      "Initialize response: {'protocolVersion': '2024-11-05', 'capabilities': {'experimental': {}, 'prompts': {'listChanged': False}, 'resources': {'subscribe': False, 'listChanged': False}, 'tools': {'listChanged': True}}, 'serverInfo': {'name': 'Weather Service 🌦️', 'version': '1.11.0'}}\n",
      "Sending initialized notification...\n",
      "Handshake completed successfully\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You: what's the weather like in Berlin?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving available tools...\n",
      "Available tools: ['get_weather', 'set_weather']\n",
      "Calling tool 'get_weather' with arguments: {'city': 'Berlin'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <details>\n",
       "            <summary>Function call: <tt>get_weather({\"city\":\"Berlin\"})</tt></summary>\n",
       "            <div>\n",
       "                <b>Call</b>\n",
       "                <pre>ResponseFunctionToolCall(arguments='{\"city\":\"Berlin\"}', call_id='call_88nTdZu1X9EgF89rU3q0albI', name='get_weather', type='function_call', id='fc_687315354dd0819d83e5093a5af66195034bd8cd3ffed4b9', status='completed')</pre>\n",
       "            </div>\n",
       "            <div>\n",
       "                <b>Output</b>\n",
       "                <pre>{\n",
       "  \"content\": [\n",
       "    {\n",
       "      \"type\": \"text\",\n",
       "      \"text\": \"20.0\"\n",
       "    }\n",
       "  ],\n",
       "  \"structuredContent\": {\n",
       "    \"result\": 20.0\n",
       "  },\n",
       "  \"isError\": false\n",
       "}</pre>\n",
       "            </div>\n",
       "            \n",
       "            </details>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <div><b>Assistant:</b></div>\n",
       "                <div><p>The weather in Berlin is currently 20.0°C. If you need more details or information, feel free to ask!</p></div>\n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You: exit\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <div><b>Assistant:</b></div>\n",
       "                <div><p>If you have any more questions in the future, feel free to reach out. Have a great day!</p></div>\n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 26\u001b[0m\n\u001b[1;32m     17\u001b[0m chat_interface \u001b[38;5;241m=\u001b[39m chat_assistant\u001b[38;5;241m.\u001b[39mChatInterface()\n\u001b[1;32m     19\u001b[0m chat \u001b[38;5;241m=\u001b[39m chat_assistant\u001b[38;5;241m.\u001b[39mChatAssistant(\n\u001b[1;32m     20\u001b[0m     tools\u001b[38;5;241m=\u001b[39mmcp_tools,\n\u001b[1;32m     21\u001b[0m     developer_prompt\u001b[38;5;241m=\u001b[39mdeveloper_prompt,\n\u001b[1;32m     22\u001b[0m     chat_interface\u001b[38;5;241m=\u001b[39mchat_interface,\n\u001b[1;32m     23\u001b[0m     client\u001b[38;5;241m=\u001b[39mclient\n\u001b[1;32m     24\u001b[0m )\n\u001b[0;32m---> 26\u001b[0m \u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/Disco_F_mnt/Documents_F/Courses/DataTalksClub/LLM_ZOOMCAMP_2025/homework-0a-agents/chat_assistant.py:99\u001b[0m, in \u001b[0;36mChatAssistant.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m# Chat loop\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m---> 99\u001b[0m     question \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat_interface\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m question\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstop\u001b[39m\u001b[38;5;124m'\u001b[39m:  \n\u001b[1;32m    101\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchat_interface\u001b[38;5;241m.\u001b[39mdisplay(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChat ended.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/mnt/Disco_F_mnt/Documents_F/Courses/DataTalksClub/LLM_ZOOMCAMP_2025/homework-0a-agents/chat_assistant.py:42\u001b[0m, in \u001b[0;36mChatInterface.input\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minput\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 42\u001b[0m     question \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mYou:\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m question\n",
      "File \u001b[0;32m~/environments/.env_dataeng/lib/python3.10/site-packages/ipykernel/kernelbase.py:1282\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1280\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1281\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[0;32m-> 1282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1283\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1284\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1285\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1287\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/environments/.env_dataeng/lib/python3.10/site-packages/ipykernel/kernelbase.py:1325\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1322\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1323\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[1;32m   1324\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1325\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1326\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You: ff\n"
     ]
    }
   ],
   "source": [
    "import chat_assistant\n",
    "\n",
    "our_mcp_client = mcp_client.MCPClient([\"python\", \"weather_server.py\"])\n",
    "\n",
    "our_mcp_client.start_server()\n",
    "our_mcp_client.initialize()\n",
    "our_mcp_client.initialized()\n",
    "\n",
    "mcp_tools = mcp_client.MCPTools(mcp_client=our_mcp_client)\n",
    "\n",
    "\n",
    "developer_prompt = \"\"\"\n",
    "You help users find out the weather in their cities. \n",
    "If they didn't specify a city, ask them. Make sure we always use a city.\n",
    "\"\"\".strip()\n",
    "\n",
    "chat_interface = chat_assistant.ChatInterface()\n",
    "\n",
    "chat = chat_assistant.ChatAssistant(\n",
    "    tools=mcp_tools,\n",
    "    developer_prompt=developer_prompt,\n",
    "    chat_interface=chat_interface,\n",
    "    client=client\n",
    ")\n",
    "\n",
    "chat.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python_3.10.12(.env_dataeng)",
   "language": "python",
   "name": ".env_dataeng"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
