{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79df4505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q \"dlt[qdrant]\" \"qdrant-client[fastembed]\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2dcf65",
   "metadata": {},
   "source": [
    "### Q1. dlt Version\n",
    "##### dlt version?\n",
    "###### Answer: 1.12.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4aeaf0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: dlt\n",
      "Version: 1.12.3\n",
      "Summary: dlt is an open-source python-first scalable data loading library that does not require any backend to run.\n",
      "Home-page: https://github.com/dlt-hub\n",
      "Author: \n",
      "Author-email: \"dltHub Inc.\" <services@dlthub.com>\n",
      "License-Expression: Apache-2.0\n",
      "Location: /Users/oleitao/Documents/Repos/DataTalks.Club/llm-zoomcamp/.venv/lib/python3.13/site-packages\n",
      "Requires: click, fsspec, gitpython, giturlparse, hexbytes, humanize, jsonpath-ng, orjson, packaging, pathvalidate, pendulum, pluggy, pytz, pyyaml, requests, requirements-parser, rich-argparse, semver, setuptools, simplejson, sqlglot, tenacity, tomlkit, typing-extensions, tzdata\n",
      "Required-by: \n",
      "dlt                     1.12.3\n",
      "qdrant-client           1.14.3\n"
     ]
    }
   ],
   "source": [
    "!pip show dlt\n",
    "!pip list | grep -E \"dlt|qdrant\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd23e988",
   "metadata": {},
   "source": [
    "### dlt use\n",
    "\n",
    "`dlt:`\n",
    "\n",
    "- Make this flow reproducible\n",
    "\n",
    "- Track state and logs\n",
    "\n",
    "- Potentially scale or schedule it\n",
    "\n",
    "`In dlt, your job is to define:`\n",
    "\n",
    "- A source → gives you the data\n",
    "\n",
    "- A resource → prepares and formats it\n",
    "\n",
    "- A pipeline → runs it and optionally loads it\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7a088f",
   "metadata": {},
   "source": [
    "### dlt (resourse)\n",
    "\n",
    "Create a resource, adding the `@dlt.resource` decorator to that function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c473c5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import dlt\n",
    "\n",
    "@dlt.resource\n",
    "def zoomcamp_data():\n",
    "    docs_url = 'https://github.com/alexeygrigorev/llm-rag-workshop/raw/main/notebooks/documents.json'\n",
    "    docs_response = requests.get(docs_url)\n",
    "    documents_raw = docs_response.json()\n",
    "\n",
    "    for course in documents_raw:\n",
    "        course_name = course['course']\n",
    "\n",
    "        for doc in course['documents']:\n",
    "            doc['course'] = course_name\n",
    "            yield doc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36819087",
   "metadata": {},
   "source": [
    "### Q2. dlt pipeline\n",
    "\n",
    "- Create a pipeline,\n",
    "\n",
    "- Define a destination for that,\n",
    "\n",
    "- Use the qdrant one.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "296ea56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#create a folder with our data, and the name for it will be db.qdrant\n",
    "from dlt.destinations import qdrant\n",
    "\n",
    "qdrant_destination = qdrant(\n",
    "  qd_path=\"db.qdrant\", \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c2a1c3",
   "metadata": {},
   "source": [
    "### pipeline\n",
    "\n",
    "A `pipeline` moves data from your Python code to a destination. The pipeline accepts `dlt` sources or resources, as well as generators, async generators, lists, and any iterables. Once the pipeline runs, all resources are evaluated and the data is loaded at the destination.\n",
    "\n",
    "##### Your pipeline instance by calling the `dlt.pipeline` function with the following arguments:\n",
    "\n",
    "`pipeline_name`: a name of the pipeline used to identify it in trace and monitoring events and to restore its state and data schemas on subsequent runs. If not provided, dlt will create a pipeline name from the file name of the currently executing Python module.\n",
    "\n",
    "`destination`: a name of the `destination` to which dlt will load the data. It may also be provided to the `run` method of the pipeline.\n",
    "\n",
    "`dataset_name`: a name of the dataset to which the data will be loaded.\n",
    "A dataset is a logical group of tables, i.e., schema in relational databases or a folder grouping many files. It may also be provided later to the `run` or `load` methods of the pipeline. If not provided, then it defaults to the `{pipeline_name}_dataset` on destinations that require datasets (most of the warehouses). It will stay empty on destinations that do not separate tables into datasets (or database schemas) ie. on vector databases or Clikchouse.\n",
    "\n",
    "> To `load` the data, you call the `run` method and pass your data in the data argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76944232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run started at 2025-07-07 14:04:38.406386+00:00 and COMPLETED in 7.26 seconds with 4 steps.\n",
      "Step extract COMPLETED in 1.43 seconds.\n",
      "\n",
      "Load package 1751897080.2907798 is EXTRACTED and NOT YET LOADED to the destination and contains no failed jobs\n",
      "\n",
      "Step normalize COMPLETED in 0.04 seconds.\n",
      "Normalized data for the following tables:\n",
      "- zoomcamp_data: 948 row(s)\n",
      "- _dlt_pipeline_state: 1 row(s)\n",
      "\n",
      "Load package 1751897080.2907798 is NORMALIZED and NOT YET LOADED to the destination and contains no failed jobs\n",
      "\n",
      "Step load COMPLETED in 3.90 seconds.\n",
      "Pipeline zoomcamp_pipeline load step completed in 3.90 seconds\n",
      "1 load package(s) were loaded to destination qdrant and into dataset zoomcamp_tagged_data\n",
      "The qdrant destination used /Users/oleitao/Documents/Repos/DataTalks.Club/llm-zoomcamp/cohorts/2025/dlt Workshop/hw/db.qdrant location to store data\n",
      "Load package 1751897080.2907798 is LOADED and contains no failed jobs\n",
      "\n",
      "Step run COMPLETED in 7.26 seconds.\n",
      "Pipeline zoomcamp_pipeline load step completed in 3.90 seconds\n",
      "1 load package(s) were loaded to destination qdrant and into dataset zoomcamp_tagged_data\n",
      "The qdrant destination used /Users/oleitao/Documents/Repos/DataTalks.Club/llm-zoomcamp/cohorts/2025/dlt Workshop/hw/db.qdrant location to store data\n",
      "Load package 1751897080.2907798 is LOADED and contains no failed jobs\n"
     ]
    }
   ],
   "source": [
    "pipeline = dlt.pipeline(\n",
    "    pipeline_name=\"zoomcamp_pipeline\",\n",
    "    destination=qdrant_destination,\n",
    "    dataset_name=\"zoomcamp_tagged_data\"\n",
    "\n",
    ")\n",
    "load_info = pipeline.run(zoomcamp_data())\n",
    "print(pipeline.last_trace)\n",
    "\n",
    "# 948"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b85239d",
   "metadata": {},
   "source": [
    "### Q2. dlt pipeline\n",
    "\n",
    "Normalized data for the following tables:\n",
    "\n",
    "- _dlt_pipeline_state: 1 row(s)\n",
    "- zoomcamp_data: 948 row(s)\n",
    "\n",
    "##### Number of inserted rows?\n",
    "###### Answer: 948\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5a2ba5",
   "metadata": {},
   "source": [
    "### Q3. Embeddings\n",
    "\n",
    "#### When inserting the data, which the embedding model used?\n",
    "\n",
    "`mata.json` -> information about db.qdrant, it used `\"fast-bge-small-en\"`\n",
    "\n",
    "here a some part of `mata.json`\n",
    "\n",
    "```json\n",
    "\"collections\": {\n",
    "        \"zoomcamp_tagged_data\": {\n",
    "            \"vectors\": {\n",
    "                \"fast-bge-small-en\": {\n",
    "                    \"size\": 384,\n",
    "                    \"distance\": \"Cosine\",\n",
    "                    \"hnsw_config\": null,\n",
    "                    \"quantization_config\": null,\n",
    "                    \"on_disk\": null,\n",
    "                    \"datatype\": null,\n",
    "                    \"multivector_config\": null\n",
    "    }\n",
    "}       \n",
    "```\n",
    "\n",
    "###### Answer: `fast-bge-small-en`\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
